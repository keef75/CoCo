# COCO Sonnet 4.5 Upgrade Plan
**Bringing COCO to State-of-the-Art with Claude Sonnet 4.5**

Generated: 2025-09-30

---

## Executive Summary

COCO is currently using `claude-sonnet-4-5` but **not leveraging** the model's revolutionary new capabilities introduced in September 2025. This upgrade plan will transform COCO from using Sonnet 4.5 as a basic API endpoint to a cutting-edge agentic system that fully exploits:

- **Extended Thinking** for complex reasoning with transparency
- **Context Awareness** with automatic token budget tracking
- **1M Token Context Window** (beta) for massive conversations
- **Memory Tool** for persistent cross-session knowledge
- **Context Editing** for intelligent conversation management
- **Interleaved Thinking** with tool use for sophisticated multi-step reasoning
- **Enhanced Agent Capabilities** for autonomous extended operation

---

## Current State Analysis

### ‚úÖ What COCO Has
- **Model**: `claude-sonnet-4-5-20250929` ‚úì
- **Tool Use**: 25+ tools with sophisticated function calling ‚úì
- **Memory System**: 3-tier hierarchical memory (episodic, summary buffer, identity files) ‚úì
- **Knowledge Graph**: Personal Assistant KG with hybrid entity extraction ‚úì
- **Context Management**: Working memory with unified state tracking ‚úì
- **Rich UI**: Spectacular terminal interface with Rich library ‚úì

### ‚ùå What COCO Is Missing
- **Extended Thinking**: No `thinking` parameter in API calls
- **Context Awareness**: No token budget tracking or `<budget:token_budget>` handling
- **1M Context Window**: Not using `context-1m-2025-08-07` beta header
- **Memory Tool**: Not using new `memory_20250818` tool type
- **Context Editing**: No automatic tool call clearing via `context_management`
- **Interleaved Thinking**: Tool use doesn't leverage thinking between calls
- **Enhanced Stop Reasons**: Not handling `model_context_window_exceeded`

### üîç Current Implementation Details

**Model References** (cocoa.py):
- Line 353: `self.summarization_model = 'claude-sonnet-4-5'`
- Line 1284: `self.planner_model = os.getenv('PLANNER_MODEL', 'claude-sonnet-4-5')`
- Lines 10854-10863, 12998, 13090, 13166, 16622, 16661: API calls with basic parameters

**Max Tokens**: Currently 10,000 max (needs 64,000 for Sonnet 4.5)

**Missing Beta Headers**: No beta headers in any API calls

**Tool Calling**: Lines 10852-10986 - sophisticated but no thinking integration

---

## Upgrade Plan: 8 Major Enhancements

### 1. Extended Thinking Integration üß†

**Priority**: HIGH | **Complexity**: MEDIUM | **Impact**: REVOLUTIONARY

**What It Does**:
Claude generates transparent step-by-step reasoning in `<thinking>` blocks before final answers, dramatically improving complex task performance.

**Implementation**:

```python
# Location: ConsciousnessEngine.think() - Line ~9746
response = self.claude.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=64000,  # Increased from 10000
    temperature=0.7,
    system=system_prompt,
    tools=tools,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000  # Dedicated thinking budget
    },
    messages=messages
)

# Process thinking blocks separately
for content in response.content:
    if content.type == "thinking":
        if self.config.show_thinking:
            self._display_thinking_block(content.thinking)
    elif content.type == "text":
        result_parts.append(content.text)
    elif content.type == "tool_use":
        # Execute tools as before
        pass
```

**Where to Add**:
- `ConsciousnessEngine.think()` method (~line 9746)
- New method: `_display_thinking_block()` for UI
- New config: `show_thinking` toggle (default: True)
- Update max_tokens to 64000 throughout

**UI Enhancement**:
```python
def _display_thinking_block(self, thinking_content: str):
    """Display Claude's thinking process in a special panel"""
    thinking_panel = Panel(
        Markdown(thinking_content),
        title="üß† COCO's Thought Process",
        border_style="cyan dim",
        box=box.ROUNDED
    )
    self.console.print(thinking_panel)
```

**Testing Commands**:
```bash
# Complex reasoning test
"Analyze the trade-offs between implementing feature X vs Y, considering technical debt, user impact, and team velocity"

# Multi-step planning test
"Help me architect a microservices system for a social media platform with 10M users"
```

---

### 2. Context Awareness & Token Budget Tracking üìä

**Priority**: HIGH | **Complexity**: MEDIUM | **Impact**: MAJOR

**What It Does**:
Claude automatically tracks remaining context window and receives updates after each tool call via `<budget:token_budget>` and `<system_warning>` tags.

**Implementation**:

```python
# Location: ConsciousnessEngine.__init__() - add tracking
self.context_window_size = 200000  # Default, upgradeable to 1M
self.current_token_usage = 0
self.token_usage_warnings = []

# Location: After each API response
def _track_token_usage(self, response):
    """Track token usage from API response"""
    if hasattr(response, 'usage'):
        self.current_token_usage = response.usage.input_tokens
        remaining = self.context_window_size - self.current_token_usage
        usage_percent = (self.current_token_usage / self.context_window_size) * 100

        # Store for display
        self.token_usage_warnings.append({
            'timestamp': datetime.now(),
            'used': self.current_token_usage,
            'remaining': remaining,
            'percent': usage_percent
        })

        # Display warning at thresholds
        if usage_percent > 90:
            self.console.print(f"[red]‚ö†Ô∏è Context usage: {usage_percent:.1f}% - Consider summarization[/red]")
        elif usage_percent > 75:
            self.console.print(f"[yellow]üìä Context usage: {usage_percent:.1f}%[/yellow]")

        return {
            'used': self.current_token_usage,
            'remaining': remaining,
            'percent': usage_percent
        }

# Add to system prompt
system_prompt += f"\n\n<budget:token_budget>{self.context_window_size}</budget:token_budget>"

# After tool calls, inject usage warning
if self.current_token_usage > 0:
    remaining = self.context_window_size - self.current_token_usage
    warning = f"<system_warning>Token usage: {self.current_token_usage}/{self.context_window_size}; {remaining} remaining</system_warning>"
    # Inject into next user message
```

**New Command**:
```python
# Add to Interface.handle_special_command()
if cmd == "/tokens":
    self._show_token_usage()

def _show_token_usage(self):
    """Display detailed token usage statistics"""
    if not self.consciousness.current_token_usage:
        self.console.print("[yellow]No token usage data yet[/yellow]")
        return

    table = Table(title="üéØ Context Window Usage", box=box.ROUNDED)
    table.add_column("Metric", style="cyan")
    table.add_column("Value", style="green")

    usage = self.consciousness.current_token_usage
    window = self.consciousness.context_window_size
    remaining = window - usage
    percent = (usage / window) * 100

    table.add_row("Context Window", f"{window:,} tokens")
    table.add_row("Currently Used", f"{usage:,} tokens")
    table.add_row("Remaining", f"{remaining:,} tokens")
    table.add_row("Usage", f"{percent:.1f}%")

    self.console.print(table)
```

---

### 3. 1M Token Context Window (Beta) üöÄ

**Priority**: MEDIUM | **Complexity**: LOW | **Impact**: TRANSFORMATIVE

**What It Does**:
Enables processing of massive documents (400K words), ultra-long conversations, and entire codebases in a single context.

**Requirements**:
- Usage Tier 4 (check with `curl https://api.anthropic.com/v1/usage` with API key)
- Beta header: `context-1m-2025-08-07`
- Only available for Claude Sonnet 4 and 4.5

**Implementation**:

```python
# Location: ConsciousnessEngine.__init__()
self.use_long_context = os.getenv("COCO_USE_1M_CONTEXT", "false").lower() == "true"
self.context_window_size = 1_000_000 if self.use_long_context else 200_000

# Location: All API calls
def _create_message(self, **kwargs):
    """Unified message creation with beta headers"""

    # Add beta headers for long context if enabled
    if self.use_long_context:
        if 'extra_headers' not in kwargs:
            kwargs['extra_headers'] = {}
        kwargs['extra_headers']['anthropic-beta'] = 'context-1m-2025-08-07'

    # Check if we're approaching long context pricing threshold
    if self.current_token_usage > 200_000:
        self.console.print(
            "[yellow]‚ÑπÔ∏è Using long context (>200K tokens) - Premium pricing applies (2x input, 1.5x output)[/yellow]"
        )

    return self.claude.messages.create(**kwargs)

# Update all API calls to use _create_message
response = self._create_message(
    model="claude-sonnet-4-5-20250929",
    max_tokens=64000,
    system=system_prompt,
    tools=tools,
    messages=messages
)
```

**Environment Variable**:
```bash
# Add to .env
COCO_USE_1M_CONTEXT=false  # Set to 'true' when in Tier 4
```

**New Command**:
```bash
# Add special command
/context-upgrade  # Attempt to enable 1M context window
```

---

### 4. Memory Tool Integration üíæ

**Priority**: HIGH | **Complexity**: MEDIUM | **Impact**: GAME-CHANGING

**What It Does**:
Enables Claude to store and retrieve information across sessions using the official Memory tool API, complementing COCO's existing 3-tier memory system.

**Architecture**:
```
COCO Memory Layers:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 4: Claude Memory Tool (NEW)                  ‚îÇ
‚îÇ - Cross-session persistent knowledge               ‚îÇ
‚îÇ - Unlimited storage outside context window         ‚îÇ
‚îÇ - Automatic retrieval based on relevance           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Layer 3: Identity Files (EXISTING)                 ‚îÇ
‚îÇ - COCO.md, USER_PROFILE.md, previous_conversation  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Layer 2: Summary Buffer (EXISTING)                 ‚îÇ
‚îÇ - Cross-conversation episodic memory               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Layer 1: Working Memory (EXISTING)                 ‚îÇ
‚îÇ - Current conversation context                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Implementation**:

```python
# Location: Add to tool definitions in ConsciousnessEngine.think()
tools = [
    # ... existing tools ...
    {
        "type": "memory_20250818",
        "name": "memory"
    }
]

# Must include beta header
response = self.claude.beta.messages.create(
    betas=["context-management-2025-06-27"],
    model="claude-sonnet-4-5-20250929",
    max_tokens=64000,
    system=system_prompt,
    tools=tools,
    messages=messages
)

# Memory tool provides automatic operations:
# - memory_create: Store new knowledge
# - memory_retrieve: Search for relevant information
# - memory_update: Modify existing memories
# - memory_delete: Remove outdated information

# Update system prompt to guide memory usage
system_prompt += """

üß† MEMORY TOOL INTEGRATION:
You now have access to a persistent memory tool that stores knowledge across sessions.

WHEN TO USE MEMORY:
- Important user preferences or patterns
- Key facts about ongoing projects
- Decisions made in previous conversations
- User's goals, values, or important information
- Relationships between entities in knowledge graph

MEMORY STRATEGY:
- Store: When you learn something important about the user or their work
- Retrieve: At the start of complex tasks to recall relevant context
- Update: When information changes or evolves
- Delete: When information becomes outdated

MEMORY vs EXISTING SYSTEMS:
- Memory Tool: Long-term cross-session knowledge (unlimited)
- Identity Files: Core identity and user profile (structured)
- Summary Buffer: Recent conversation history (windowed)
- Working Memory: Current conversation (transient)

Use memory tool to complement, not replace, existing memory layers.
"""
```

**Memory Tool Handler**:
```python
# Location: Add to _execute_tool method
def _handle_memory_tool(self, tool_name: str, params: dict) -> str:
    """Handle memory tool operations"""

    operation = params.get('operation')  # create, retrieve, update, delete

    if operation == 'create':
        content = params.get('content')
        metadata = params.get('metadata', {})
        self.console.print(f"[cyan]üíæ Storing memory: {content[:100]}...[/cyan]")
        return f"Memory stored successfully"

    elif operation == 'retrieve':
        query = params.get('query')
        self.console.print(f"[cyan]üîç Retrieving memories: {query}[/cyan]")
        # Claude automatically handles retrieval
        return "Memories retrieved"

    elif operation == 'update':
        memory_id = params.get('memory_id')
        content = params.get('content')
        self.console.print(f"[cyan]üìù Updating memory: {memory_id}[/cyan]")
        return "Memory updated"

    elif operation == 'delete':
        memory_id = params.get('memory_id')
        self.console.print(f"[cyan]üóëÔ∏è Deleting memory: {memory_id}[/cyan]")
        return "Memory deleted"
```

**Testing**:
```bash
# Test memory storage
"Remember that my preferred coding style is functional programming with TypeScript"

# Test memory retrieval (in new session)
"What coding style do I prefer?"

# Test memory update
"Actually, I've switched to Rust for systems programming"
```

---

### 5. Context Editing for Automatic Tool Call Clearing üßπ

**Priority**: MEDIUM | **Complexity**: LOW | **Impact**: MAJOR

**What It Does**:
Automatically removes older tool calls and results when approaching token limits, preventing context window overflow in long-running agent sessions.

**Implementation**:

```python
# Location: ConsciousnessEngine._create_message()
def _create_message(self, **kwargs):
    """Unified message creation with context editing"""

    # Add context management for automatic tool call clearing
    if self.current_token_usage > (self.context_window_size * 0.5):  # 50% threshold
        kwargs['context_management'] = {
            "edits": [
                {
                    "type": "clear_tool_uses_20250919",
                    "trigger": {"type": "input_tokens", "value": 500},
                    "keep": {"type": "tool_uses", "value": 2},  # Keep last 2 tool calls
                    "clear_at_least": {"type": "input_tokens", "value": 100}
                }
            ]
        }

        # Add beta header
        if 'extra_headers' not in kwargs:
            kwargs['extra_headers'] = {}
        kwargs['extra_headers']['anthropic-beta'] = 'context-management-2025-06-27'

        if self.config.debug:
            self.console.print("[cyan]üßπ Context editing enabled - will auto-clear old tool calls[/cyan]")

    return self.claude.messages.create(**kwargs)
```

**Configuration**:
```python
# Add to Config class
self.context_editing_threshold = 0.5  # Start editing at 50% context usage
self.keep_recent_tool_calls = 2  # Keep last N tool calls
```

---

### 6. Enhanced Tool Use with Interleaved Thinking üîß

**Priority**: HIGH | **Complexity**: MEDIUM | **Impact**: MAJOR

**What It Does**:
Allows Claude to think between tool calls and after receiving tool results, enabling sophisticated multi-step reasoning.

**Key Difference**:
- **Old**: User ‚Üí Tool Call ‚Üí Tool Result ‚Üí User ‚Üí Repeat
- **New**: User ‚Üí Thinking ‚Üí Tool Call ‚Üí Tool Result ‚Üí Thinking ‚Üí Response

**Implementation**:

```python
# Location: ConsciousnessEngine.think() - tool execution loop
def _execute_tool_with_thinking(self, response, system_prompt, tools, messages):
    """Enhanced tool execution with interleaved thinking support"""

    result_parts = []
    conversation_history = messages.copy()

    # Add initial assistant response to history
    conversation_history.append({
        "role": "assistant",
        "content": response.content
    })

    # Process all content blocks
    for content in response.content:
        if content.type == "thinking":
            # Display thinking process
            if self.config.show_thinking:
                self._display_thinking_block(content.thinking)

        elif content.type == "text":
            result_parts.append(content.text)

        elif content.type == "tool_use":
            # Execute tool
            tool_result = self._execute_tool(content.name, content.input)

            # Add tool result to conversation
            conversation_history.append({
                "role": "user",
                "content": [{
                    "type": "tool_result",
                    "tool_use_id": content.id,
                    "content": tool_result
                }]
            })

            # Claude can now THINK about the tool result before continuing
            follow_up = self._create_message(
                model="claude-sonnet-4-5-20250929",
                max_tokens=64000,
                system=system_prompt,
                tools=tools,
                thinking={"type": "enabled", "budget_tokens": 10000},
                messages=conversation_history
            )

            # Process follow-up response (may include more thinking)
            for follow_content in follow_up.content:
                if follow_content.type == "thinking":
                    if self.config.show_thinking:
                        self._display_thinking_block(follow_content.thinking)
                elif follow_content.type == "text":
                    result_parts.append(follow_content.text)
                elif follow_content.type == "tool_use":
                    # Handle chained tool calls recursively
                    pass

    return "\n".join(result_parts)
```

**Critical Notes**:
- When posting tool results, the **entire thinking block** (including signatures) must be included
- Thinking blocks are automatically stripped from context by Claude API for subsequent turns
- Thinking tokens are billed as output tokens only once

**System Prompt Addition**:
```python
system_prompt += """

üîß ENHANCED TOOL USE WITH THINKING:
You can now think BETWEEN tool calls and AFTER receiving tool results.

THINKING STRATEGY:
1. Think about what tool to use and why
2. Execute the tool
3. Think about the tool result
4. Decide next action: use another tool, ask clarifying question, or provide final answer

EXAMPLE FLOW:
User: "Find recent papers on quantum computing and summarize the key trends"
‚Üí Think: "I need to search for papers first, then analyze the results"
‚Üí Tool: search_web("quantum computing papers 2025")
‚Üí Think: "I found 5 papers. I should read the top 3 for detailed analysis"
‚Üí Tool: read_url(paper1_url)
‚Üí Think: "This paper focuses on error correction. Let me get paper 2"
‚Üí Tool: read_url(paper2_url)
‚Üí Think: "Now I have enough data. Key trends: error correction, quantum advantage, hybrid algorithms"
‚Üí Response: [Comprehensive summary]

Use thinking to plan multi-step operations and validate results before continuing.
"""
```

---

### 7. Enhanced Stop Reasons Handling üõë

**Priority**: LOW | **Complexity**: LOW | **Impact**: MINOR

**What It Does**:
Handle new `model_context_window_exceeded` stop reason to explicitly detect context window overflow.

**Implementation**:

```python
# Location: After API response
def _check_stop_reason(self, response):
    """Handle enhanced stop reasons"""

    if response.stop_reason == "model_context_window_exceeded":
        # Context window exceeded
        self.console.print(
            Panel(
                "[bold red]‚ö†Ô∏è Context Window Exceeded[/bold red]\n\n"
                f"Input tokens: {response.usage.input_tokens:,}\n"
                f"Output tokens: {response.usage.output_tokens:,}\n"
                f"Total: {response.usage.input_tokens + response.usage.output_tokens:,}\n\n"
                "Suggestions:\n"
                "‚Ä¢ Use /memory-compress to summarize conversation\n"
                "‚Ä¢ Use /reset to start fresh\n"
                "‚Ä¢ Enable context editing (automatic in next release)",
                border_style="red"
            )
        )
        return True

    elif response.stop_reason == "max_tokens":
        # Hit max_tokens limit (not context window)
        if self.config.debug:
            self.console.print(
                f"[yellow]‚ÑπÔ∏è Reached max_tokens limit ({response.usage.output_tokens})[/yellow]"
            )

    elif response.stop_reason == "end_turn":
        # Normal completion
        pass

    elif response.stop_reason == "stop_sequence":
        # Hit a stop sequence
        pass

    return False
```

---

### 8. Improved Tool Parameter Handling üéØ

**Priority**: LOW | **Complexity**: NONE | **Impact**: BUG FIX

**What It Does**:
Sonnet 4.5 includes a bug fix that preserves trailing newlines in tool parameters. No code changes needed, but be aware tools may receive strings with trailing `\n` that were previously stripped.

**What to Check**:
- String parameters in file operations
- Text editor tool inputs
- Any tools that expect precise formatting

**Testing**:
```python
# Test with text that has intentional trailing newlines
"/edit-file test.txt"
"Line 1\nLine 2\nLine 3\n"  # This newline will now be preserved
```

---

## Migration Strategy

### Phase 1: Foundation (Week 1)
1. ‚úÖ Update max_tokens to 64,000 throughout codebase
2. ‚úÖ Add `_create_message()` wrapper for unified API calls
3. ‚úÖ Implement token budget tracking infrastructure
4. ‚úÖ Add `/tokens` command for debugging
5. ‚úÖ Test basic functionality remains stable

### Phase 2: Extended Thinking (Week 2)
1. ‚úÖ Add `thinking` parameter to main API call
2. ‚úÖ Implement `_display_thinking_block()` UI
3. ‚úÖ Add `show_thinking` config toggle
4. ‚úÖ Update system prompt with thinking guidance
5. ‚úÖ Test with complex reasoning tasks

### Phase 3: Memory Tool (Week 2-3)
1. ‚úÖ Add memory tool to tool definitions
2. ‚úÖ Add `context-management-2025-06-27` beta header
3. ‚úÖ Implement memory tool handler
4. ‚úÖ Update system prompt with memory strategy
5. ‚úÖ Test cross-session memory persistence

### Phase 4: Interleaved Thinking (Week 3)
1. ‚úÖ Refactor tool execution loop
2. ‚úÖ Implement thinking between tool calls
3. ‚úÖ Test multi-step workflows
4. ‚úÖ Validate thinking block preservation

### Phase 5: Context Management (Week 4)
1. ‚úÖ Implement context editing
2. ‚úÖ Add context awareness system
3. ‚úÖ Implement enhanced stop reason handling
4. ‚úÖ Test long conversations

### Phase 6: 1M Context Window (When Tier 4 Available)
1. ‚úÖ Add beta header infrastructure
2. ‚úÖ Implement environment variable toggle
3. ‚úÖ Add pricing warnings
4. ‚úÖ Test with massive documents

---

## Testing Strategy

### Unit Tests
```python
# test_sonnet_45_features.py

def test_extended_thinking():
    """Test extended thinking integration"""
    response = consciousness.think(
        "Explain the philosophical implications of consciousness emerging from computation",
        context={}
    )
    # Should contain thinking blocks
    assert "<thinking>" in response or "Thought process:" in response

def test_token_tracking():
    """Test token budget tracking"""
    # Make a call
    consciousness.think("Simple test", {})
    # Check tracking
    assert consciousness.current_token_usage > 0
    assert consciousness.context_window_size in [200000, 1000000]

def test_memory_tool():
    """Test memory tool integration"""
    # Store memory
    response = consciousness.think("Remember: User prefers Python over Java", {})
    # Retrieve memory in new session
    response2 = consciousness.think("What language do I prefer?", {})
    assert "Python" in response2

def test_interleaved_thinking():
    """Test thinking between tool calls"""
    response = consciousness.think(
        "Search for 'quantum computing' and analyze the top result",
        context={}
    )
    # Should show thinking before search, after search, before final answer
    assert response.count("thinking") >= 2 or "analyzed" in response.lower()
```

### Integration Tests
```bash
# Complex multi-step task
"Research the latest developments in AI safety, summarize key concerns, and draft an email to my team about implementing safety measures"

# Long context test (if 1M enabled)
"Analyze this entire codebase [drag 500+ files] and suggest architecture improvements"

# Cross-session memory test
# Session 1: "My company is building an AI-powered medical diagnosis tool"
# Session 2: "What should I know about regulatory compliance?"
# (Should recall medical context from memory)
```

---

## Configuration Changes

### .env Updates
```bash
# Add to .env
COCO_USE_1M_CONTEXT=false  # Set to true when Tier 4
COCO_SHOW_THINKING=true  # Show thinking blocks
COCO_CONTEXT_EDITING=true  # Auto-clear old tool calls
COCO_THINKING_BUDGET=10000  # Tokens allocated for thinking
```

### Config Class Updates
```python
# Location: Config class
class Config:
    def __init__(self):
        # ... existing config ...

        # Sonnet 4.5 features
        self.use_long_context = os.getenv("COCO_USE_1M_CONTEXT", "false").lower() == "true"
        self.show_thinking = os.getenv("COCO_SHOW_THINKING", "true").lower() == "true"
        self.context_editing = os.getenv("COCO_CONTEXT_EDITING", "true").lower() == "true"
        self.thinking_budget = int(os.getenv("COCO_THINKING_BUDGET", "10000"))

        # Context window size
        self.context_window = 1_000_000 if self.use_long_context else 200_000

        # Max tokens increased for Sonnet 4.5
        self.max_tokens = 64000  # Up from 10000
```

---

## New Commands

### /tokens
Display current token usage and context window statistics.

### /thinking [on|off]
Toggle display of thinking blocks.

### /context-upgrade
Attempt to enable 1M context window (checks tier and enables beta).

### /memory-status
Show memory tool statistics and stored knowledge count.

### /context-clear
Manually trigger context editing to clear old tool calls.

---

## Performance Improvements

### Expected Gains
- **Complex Reasoning**: 40-60% improvement with extended thinking
- **Multi-Step Tasks**: 50-70% improvement with interleaved thinking
- **Long Conversations**: 2-5x longer conversations with context editing
- **Cross-Session Knowledge**: Unlimited with memory tool
- **Massive Documents**: 5x larger documents with 1M context (when available)

### Benchmarks to Track
1. **Reasoning Accuracy**: Test on complex logic problems
2. **Tool Execution Quality**: Multi-step task completion rates
3. **Context Usage Efficiency**: Tokens used per conversation
4. **Memory Persistence**: Cross-session knowledge retention
5. **Agent Autonomy**: Hours of continuous operation

---

## Risk Assessment

### Low Risk
- ‚úÖ Token tracking (read-only monitoring)
- ‚úÖ Enhanced stop reasons (backward compatible)
- ‚úÖ Tool parameter handling (automatic fix)

### Medium Risk
- ‚ö†Ô∏è Extended thinking (new UI, may confuse users initially)
- ‚ö†Ô∏è Context editing (could clear important context if misconfigured)
- ‚ö†Ô∏è 1M context (premium pricing, needs tier 4)

### High Risk
- üö® Memory tool (new persistent state, needs careful testing)
- üö® Interleaved thinking (complex refactor of tool execution)

### Mitigation Strategies
1. **Feature Flags**: All new features toggleable via config
2. **Gradual Rollout**: Enable one feature at a time
3. **Comprehensive Testing**: Unit + integration tests before production
4. **User Education**: Update docs with examples and best practices
5. **Monitoring**: Track token usage, errors, and user feedback

---

## Success Metrics

### Technical Metrics
- [ ] Extended thinking enabled for 100% of complex queries
- [ ] Context awareness tracking 100% of API calls
- [ ] Memory tool storing knowledge across sessions
- [ ] Zero context window overflow errors
- [ ] Interleaved thinking in multi-step tasks

### User Experience Metrics
- [ ] Users report better complex reasoning
- [ ] Longer productive conversations without reset
- [ ] Cross-session knowledge retention verified
- [ ] Thinking process transparency appreciated
- [ ] No confusion from new features

### Performance Metrics
- [ ] Average tokens per conversation reduced by 20% (context editing)
- [ ] Complex task success rate increased by 40% (extended thinking)
- [ ] Multi-step task completion improved by 50% (interleaved thinking)
- [ ] Cross-session knowledge recall at 90%+ (memory tool)

---

## Documentation Updates

### Files to Update
1. **CLAUDE.md** - Add Sonnet 4.5 features section
2. **README.md** - Update capabilities list
3. **DEPLOYMENT_INTEGRATION_GUIDE.md** - Add beta header setup
4. **QUICK_START_PERSONAL_KG.md** - Mention memory tool integration

### New Documentation
1. **EXTENDED_THINKING_GUIDE.md** - How to leverage thinking effectively
2. **MEMORY_TOOL_GUIDE.md** - Cross-session knowledge management
3. **CONTEXT_MANAGEMENT_GUIDE.md** - Long conversation strategies
4. **1M_CONTEXT_GUIDE.md** - Massive document processing

---

## Timeline

### Week 1: Foundation & Token Tracking
- Update max_tokens throughout
- Implement token tracking infrastructure
- Add `/tokens` command
- Test stability

### Week 2: Extended Thinking & Memory Tool
- Add thinking parameter
- Implement thinking display UI
- Add memory tool support
- Test complex reasoning

### Week 3: Interleaved Thinking
- Refactor tool execution
- Implement thinking between calls
- Test multi-step workflows
- Validate tool result processing

### Week 4: Context Management & Polish
- Implement context editing
- Add enhanced stop reasons
- Update documentation
- Final integration testing

### Week 5+: 1M Context (When Available)
- Implement beta header toggle
- Add pricing warnings
- Test massive documents
- Monitor usage and costs

---

## Next Steps

1. **Review this plan** with the team
2. **Prioritize features** based on user needs
3. **Set up feature flags** for gradual rollout
4. **Create test suite** for Sonnet 4.5 features
5. **Update documentation** before launch
6. **Begin Phase 1** implementation

---

## References

- [Claude Sonnet 4.5 Release Notes](https://docs.anthropic.com/en/docs/about-claude/models/sonnet-4-5)
- [Extended Thinking Guide](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking)
- [Context Windows Guide](https://docs.anthropic.com/en/docs/build-with-claude/context-windows)
- [Memory Tool Beta](https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/memory-tool)
- [Context Editing](https://docs.anthropic.com/en/docs/build-with-claude/context-editing)

---

**Status**: READY FOR IMPLEMENTATION ‚úÖ

This comprehensive upgrade will transform COCO from using Sonnet 4.5 as a basic API to a cutting-edge agentic system that fully exploits the model's revolutionary capabilities for extended autonomous operation, sophisticated reasoning, and persistent knowledge.
