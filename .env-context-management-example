# ============================================================================
# CONTEXT WINDOW MANAGEMENT - Optional Configuration
# ============================================================================
# These variables control COCO's automatic context window management system.
# Default values work well for most use cases - only modify if needed.

# Context Warning Threshold (90% of 200K limit)
# When context usage exceeds this, emergency compression is triggered
# Default: 180000 (90% of 200K token limit)
CONTEXT_WARNING_THRESHOLD=180000

# Context Critical Threshold (95% of 200K limit)
# When context usage exceeds this, conversation checkpoint is created
# Default: 190000 (95% of 200K token limit)
CONTEXT_CRITICAL_THRESHOLD=190000

# Working Memory Maximum Tokens
# Maximum tokens to use for working memory context injection
# Default: 150000 (75% of 200K token limit)
WORKING_MEMORY_MAX_TOKENS=150000

# Emergency Retention Count
# Number of recent exchanges to keep during emergency compression
# Default: 20
EMERGENCY_RETAIN_EXCHANGES=20

# Summarization Model
# Model used for emergency compression and checkpoint summaries
# Default: claude-3-haiku-20240307 (fast + cheap)
# Alternative: claude-sonnet-4-5-20250929 (higher quality but 10x more expensive)
SUMMARIZATION_MODEL=claude-3-haiku-20240307

# ============================================================================
# USAGE NOTES
# ============================================================================
#
# NORMAL OPERATION (<70% context):
# - No compression triggers
# - Full working memory included
# - No user-visible changes
#
# WARNING ZONE (70-90%):
# - Adaptive truncation of older exchanges
# - Compression marker shown if needed
# - No automatic compression yet
#
# EMERGENCY ZONE (90-95%):
# - Automatic emergency compression
# - Older exchanges summarized into RAG
# - Last 20 exchanges retained
# - Yellow warnings shown to user
#
# CRITICAL ZONE (>95%):
# - Automatic checkpoint creation
# - Comprehensive conversation summary
# - Context window refreshed
# - Red alerts shown to user
#
# ============================================================================
# COST IMPLICATIONS
# ============================================================================
#
# Using default Haiku model:
# - Emergency compression: ~$0.10 per compression
# - Checkpoint creation: ~$0.20 per checkpoint
# - Typical long conversation (5000 exchanges): ~$1-2 total
#
# Using Sonnet model (if changed):
# - Emergency compression: ~$1.00 per compression
# - Checkpoint creation: ~$2.00 per checkpoint
# - Typical long conversation (5000 exchanges): ~$10-20 total
#
# ============================================================================
# PERFORMANCE NOTES
# ============================================================================
#
# - Token estimation: <1ms (instant)
# - Emergency compression: 2-3 seconds (Haiku API call)
# - Checkpoint creation: 3-5 seconds (Haiku API call)
# - Normal conversation: 0ms overhead
#
# ============================================================================
# TROUBLESHOOTING
# ============================================================================
#
# If you see frequent compressions:
# - Lower WORKING_MEMORY_MAX_TOKENS to compress earlier
# - Increase EMERGENCY_RETAIN_EXCHANGES to keep more context
#
# If you want more aggressive compression:
# - Lower CONTEXT_WARNING_THRESHOLD (e.g., 150000 = 75%)
# - Lower WORKING_MEMORY_MAX_TOKENS (e.g., 100000 = 50%)
#
# If you want fewer compressions:
# - Raise CONTEXT_WARNING_THRESHOLD (e.g., 185000 = 92.5%)
# - Raise WORKING_MEMORY_MAX_TOKENS (e.g., 170000 = 85%)
#
# If compression fails:
# - Check ANTHROPIC_API_KEY is valid
# - Verify Haiku model availability
# - Check internet connection
# - Fallback: Use /memory buffer clear manually
#
# ============================================================================
# MONITORING
# ============================================================================
#
# Check context usage anytime with:
# /memory status
#
# This shows:
# - Current context usage percentage
# - Token breakdown by component
# - Recent compressions/checkpoints
# - Recommendations based on usage
#
# ============================================================================
